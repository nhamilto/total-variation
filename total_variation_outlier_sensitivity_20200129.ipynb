{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metmast signals\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-deep')\n",
    "import inspect\n",
    "import scipy as sp\n",
    "import scipy.optimize as sciop\n",
    "\n",
    "import total_var_functions as TV\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "def total_variation(data,\n",
    "                    blocksize=60,\n",
    "                    detrend=None,\n",
    "                    column=None,\n",
    "                    window='slide',\n",
    "                    fitcurve=None\n",
    "                   ):\n",
    "    '''\n",
    "    Calculate the total variation of a dataset.\n",
    "    Data is cut into blocks sequentially (window='block') or with a\n",
    "    sliding window (window='slide'). \n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: df.DataFrame, np.ndarray\n",
    "        input data of format (timeseries x datachannels)\n",
    "\n",
    "    blocksize: int\n",
    "        size of blocks for which to calculate total variation\n",
    "        blocksize reflects the duration of each period in minutes\n",
    "\n",
    "    detrend: None, list\n",
    "        list of variables to detrend (linear)\n",
    "        \n",
    "    column: str\n",
    "        name of column to detrend\n",
    "    \n",
    "    window: str\n",
    "        'block' - sequential, non overlapping windows\n",
    "        'slide' - overlapping windows of length 'blocksize' at each index\n",
    "\n",
    "    fitcurve: str\n",
    "        specify the fit function to use for detrending.\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    totalvar: df.Series\n",
    "        Series of the total variation for each time period.\n",
    "    '''\n",
    "\n",
    "    if window == 'slide':\n",
    "        timeind = data.index\n",
    "    elif window == 'block':\n",
    "        # make new time index (hourly)\n",
    "        timeind = pd.date_range(start=data.index[0],\n",
    "                                   freq='{}T'.format(blocksize),\n",
    "                                   end=data.index[-1])\n",
    "\n",
    "    nblocks = len(timeind) \n",
    "\n",
    "    # allocate space for totalvar\n",
    "    totalvar = np.zeros(nblocks)\n",
    "\n",
    "    # if detrending data, parse objective functino, and the number of required arguments\n",
    "    if detrend is not None:\n",
    "        fitfunc, param_names = TV.parse_fitfunc(detrend)\n",
    "        param_names.append('residual')\n",
    "        tmp = inspect.getfullargspec(fitfunc)\n",
    "        nargs = len(tmp.args)\n",
    "        fits = np.zeros((nblocks, nargs))  # slope, offset, residual\n",
    "        x = np.arange(blocksize)\n",
    "\n",
    "    nskip = 0\n",
    "    timedelay = pd.Timedelta('{}m'.format(blocksize - 1))\n",
    "\n",
    "    # loop over data blocks\n",
    "    for ii in range(nblocks - 1):\n",
    "\n",
    "        startind = timeind[ii]\n",
    "        endind = startind + timedelay\n",
    "\n",
    "        block = data[startind:endind].dropna(how='any').copy()\n",
    "\n",
    "        if (len(block) < blocksize) | (any(block.std() == 0)):\n",
    "            nskip += 1\n",
    "            continue\n",
    "\n",
    "        if detrend is not None:\n",
    "            p0 = TV.parse_init_fitvals(detrend, block[column].values)\n",
    "\n",
    "            try:\n",
    "                fittest = sciop.curve_fit(fitfunc, x, block[column], p0)\n",
    "                fitparams, _ = fittest\n",
    "                fitcurve = fitfunc(x, *fitparams)\n",
    "                residual = np.linalg.norm(block[column] -\n",
    "                                          fitfunc(x, *fitparams))**2\n",
    "            except:\n",
    "                print('fit failed')\n",
    "                fitparams = p0\n",
    "                fitcurve = fitfunc(x, *fitparams)\n",
    "                residual = np.nan\n",
    "\n",
    "            block[column] -= (fitcurve + block[column].mean())\n",
    "            fits[ii, :-1] = fitparams\n",
    "            fits[ii, -1] = np.linalg.norm(residual)\n",
    "\n",
    "        totalvar[ii] = TV.covdet(TV.standardize_data(block))\n",
    "\n",
    "    # make dataframe for total variation\n",
    "    totalvar = pd.DataFrame(data=totalvar, index=timeind, columns=['totalvar'])\n",
    "\n",
    "    # if data has been detrended, add fit parameter columns to output dataframe\n",
    "    if detrend is not None:\n",
    "\n",
    "        fitcols = {'_'.join([column, x]): np.array([]) for x in param_names}\n",
    "        fits = pd.DataFrame(index=totalvar.index, data=fits, columns=fitcols)\n",
    "        totalvar = totalvar.join(fits)\n",
    "    \n",
    "    # replace 0.0 with np.nan\n",
    "    totalvar.replace(0, np.nan, inplace=True)\n",
    "    # Drop all nan values\n",
    "    totalvar.dropna(inplace=True, how='all')\n",
    "\n",
    "\n",
    "    return totalvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load meteorological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### read pre-processed data.\n",
    "metdf = pd.read_csv('metdata1T.csv')\n",
    "\n",
    "# metdf = pd.read_csv('../../../data/metdata_2009.csv')\n",
    "metdf.dropna(how='any', inplace=True)\n",
    "metdf.index = pd.DatetimeIndex(metdf['Unnamed: 0'])\n",
    "metdf.drop(labels=['Unnamed: 0'], axis=1, inplace=True)\n",
    "metdf.index.name = 'time'\n",
    "# standardize data\n",
    "# metdfnorm = TV.standardize_data(metdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/numpy/linalg/linalg.py:2093: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    }
   ],
   "source": [
    "tvar = total_variation(metdf, blocksize=60, window='block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvarLinear = total_variation(metdf, \n",
    "                       blocksize=60, \n",
    "                       window='block', \n",
    "                       detrend='linear', \n",
    "                       column='WS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvarWave = total_variation(metdf, \n",
    "                       blocksize=60, \n",
    "                       window='block', \n",
    "                       detrend='sine', \n",
    "                       column='WS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "\n",
    "tvar.plot.hist(bins=25, edgecolor='k', ax=ax, alpha=0.7)\n",
    "tvarLinear['totalvar'].plot.hist(bins=25, edgecolor='k', ax=ax, alpha=0.7)\n",
    "tvarWave['totalvar'].plot.hist(bins=25, edgecolor='k', ax=ax, alpha=0.7)\n",
    "ax.legend(['f=0', 'linear', 'sine'])\n",
    "\n",
    "fig.savefig('figs/tvar_detrend_distributions.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvar_sort = tvar.sort_values('totalvar', ascending=False).copy()\n",
    "starttimes = list(tvar_sort.index[0:5])\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(5,9))\n",
    "\n",
    "blocksize = 60\n",
    "dummyindex = pd.timedelta_range(start = 0, periods=blocksize, freq='1T')\n",
    "for ii in starttimes:\n",
    "    plotdat = metdf.loc[ii:ii+pd.Timedelta(blocksize-1, 'T')]\n",
    "    plotdat.index = dummyindex\n",
    "    \n",
    "    ax[0].plot(plotdat.WS)\n",
    "    ax[1].plot(plotdat.WD)\n",
    "    ax[2].plot(plotdat.TI)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvar_sort = tvar.sort_values('totalvar', ascending=True).copy()\n",
    "starttimes = list(tvar_sort.index[0:5])\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(5,9))\n",
    "\n",
    "blocksize = 60\n",
    "dummyindex = pd.timedelta_range(start = 0, periods=blocksize, freq='1T')\n",
    "for ii in starttimes:\n",
    "    plotdat = metdf.loc[ii:ii+pd.Timedelta(blocksize-1, 'T')]\n",
    "    plotdat.index = dummyindex\n",
    "    \n",
    "    ax[0].plot(plotdat.WS)\n",
    "    ax[1].plot(plotdat.WD)\n",
    "    ax[2].plot(plotdat.TI)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis distance\n",
    "\n",
    "True Mahalanobis distance:\n",
    "\n",
    "$$MD = \\sqrt{(x-\\mu)^T C^{-1} (x-\\mu)}$$\n",
    "\n",
    "where $x$ is the input data, and $\\mu$ is the center of the data determined as the mean along each coodinate variable. In reality, there are a finite number of observations of $x$ and the mean and covariance matrix must be estimated,\n",
    "\n",
    "$$MD = \\sqrt{(x-\\hat{\\mu})^T \\hat{C}^{-1} (x-\\hat{\\mu})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_error = np.zeros(10000)\n",
    "noutliers = outlier_error.copy()\n",
    "t = outlier_error.copy()\n",
    "tc = outlier_error.copy()\n",
    "datasize = 1000\n",
    "\n",
    "for ii in range(len(outlier_error)):\n",
    "    \n",
    "    shape_factor = np.random.rand(2)\n",
    "    scale = np.random.rand(1)*100\n",
    "    rotation_angle = np.random.rand(1)*2*np.pi\n",
    "    rotation_matrix = np.array([[np.cos(rotation_angle), np.sin(rotation_angle)],[np.sin(rotation_angle), -np.cos(rotation_angle)]]).squeeze()\n",
    "\n",
    "    synthetic_data = TV.standardize_data(np.random.normal(size=(datasize,2), scale=scale))\n",
    "    synthetic_data = np.matmul(synthetic_data*shape_factor, rotation_matrix)\n",
    "    clean_data, outliers, outlier_index = TV.find_outliers(synthetic_data, searchtype='mahal')\n",
    "\n",
    "    t[ii] = TV.covdet(synthetic_data)\n",
    "    tc[ii] = TV.covdet(clean_data)\n",
    "    \n",
    "    noutliers[ii] = len(outlier_index)\n",
    "    outlier_error[ii] = (t[ii]-tc[ii])/t[ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfout = pd.DataFrame(data=np.vstack([noutliers, outlier_error]).T, columns=['n_outliers', 'error'])\n",
    "\n",
    "outlier_stats = dfout.groupby('n_outliers').describe()\n",
    "\n",
    "outlier_stats.columns = ['_'.join(col).strip() for col in outlier_stats.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot of a single sample of synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasize=1000\n",
    "\n",
    "shape_factor = [1,1/3]# np.random.rand(2)\n",
    "# scale = np.random.rand(1)*40\n",
    "rotation_angle = [40]#np.random.rand(1)*2*np.pi\n",
    "rotation_matrix = np.array([[np.cos(rotation_angle), np.sin(rotation_angle)],[np.sin(rotation_angle), -np.cos(rotation_angle)]]).squeeze()\n",
    "\n",
    "synthetic_data = TV.standardize_data(np.random.normal(size=(datasize,2)))\n",
    "synthetic_data = np.matmul(synthetic_data*shape_factor, rotation_matrix)\n",
    "clean_data, outliers, outlier_index = TV.find_outliers(synthetic_data, searchtype='mahal')\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "scat = ax.scatter(clean_data[:,0], clean_data[:,1], facecolor='C0', edgecolor='k', alpha=0.75)\n",
    "outs = ax.scatter(outliers[:,0], outliers[:,1], facecolor='C2', edgecolor='k', alpha=0.75)\n",
    "ax.set_aspect('equal', 'box')\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlabel('Normalized Data')\n",
    "ax.set_ylabel('Normalized Data')\n",
    "ax.legend([scat, outs], ['Data', 'Outlier'], frameon=True, edgecolor='k')#, loc=3)\n",
    "fig.savefig(os.path.join('figs/data_w_outliers.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax.bar( outlier_stats.index, outlier_stats.error_count, facecolor='C0', edgecolor='k', alpha=0.75, width=1, linewidth=1)\n",
    "ax.set_xlabel('Number of Outliers')\n",
    "ax.set_ylabel('Number of Cases')\n",
    "fig.savefig(os.path.join('figs/outliers_by_dummy_case.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "xdata = outlier_stats.index/datasize*100\n",
    "\n",
    "ax.plot(xdata, 100*outlier_stats.error_mean)\n",
    "\n",
    "upper_error = 100*(outlier_stats.error_mean + outlier_stats.error_std)\n",
    "lower_error = 100*(outlier_stats.error_mean - outlier_stats.error_std)\n",
    "ax.fill_between(xdata, upper_error, lower_error, color='C2', alpha=0.75)\n",
    "\n",
    "upper_error = 100*(outlier_stats.error_mean + outlier_stats.error_std/np.sqrt(outlier_stats.error_count))\n",
    "lower_error = 100*(outlier_stats.error_mean - outlier_stats.error_std/np.sqrt(outlier_stats.error_count))\n",
    "ax.fill_between(xdata, upper_error, lower_error, color='C1', alpha=0.75)\n",
    "\n",
    "ax.set_xlabel('Sample Outlier Content [\\%]')\n",
    "ax.set_ylabel(r'Average Error of $\\mathcal{V}$ [\\%]')\n",
    "ax.set_xlim([200/datasize,2100/datasize])\n",
    "\n",
    "ax.legend(['Mean Error', r'$\\pm$ Standard Devation', r'$\\pm$ Standard Error'])\n",
    "fig.savefig(os.path.join('figs/outliers_average_error.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(5,3))\n",
    "bins = np.linspace(0,0.15,35)\n",
    "\n",
    "ax.hist(t, bins=bins, facecolor='C1', alpha=0.75, edgecolor='k', weights=np.ones(len(t))/len(t)*100)\n",
    "ax.hist(tc, bins=bins, facecolor='C2', alpha=0.75, edgecolor='k', weights=np.ones(len(t))/len(t)*100)\n",
    "ax.legend(['Raw', 'Clean'])\n",
    "\n",
    "ax.set_xlabel(r'Total Variation [-]')\n",
    "ax.set_ylabel(r'Frequency [\\%]')\n",
    "\n",
    "fig.savefig(os.path.join('figs/tvar_dummy_data.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
